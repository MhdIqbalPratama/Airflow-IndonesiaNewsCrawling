{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "from urllib.request import Request, urlopen\n",
    "import json\n",
    "import re\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONNECTION_STRING = f\"mongodb://localhost:27017/?readPreference=primary&directConnection=true\"\n",
    "#lient = MongoClient(CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database for each portal news\n",
    "def get_database():\n",
    "  CONNECTION_STRING = f\"mongodb://localhost:27017/?readPreference=primary&directConnection=true\"\n",
    "  client = MongoClient(CONNECTION_STRING)\n",
    "  return client['News']\n",
    "\n",
    "db = get_database()\n",
    "kompas_db = db['Kompas']\n",
    "tribun_db = db['Tribun']\n",
    "detik_db = db['Detik']\n",
    "cnn_db = db['Cnn']\n",
    "okezone_db = db['Okezone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class crawl every portal news per 2023-06-28\n",
    "def kompas_crawl():\n",
    "  url = f\"https://indeks.kompas.com/?site=all&date=2023-06-28&page=3\"\n",
    "  page = urlopen(url)\n",
    "  html = page.read().decode(\"utf-8\")\n",
    "  soup = BeautifulSoup(html, \"html.parser\")\n",
    "  paging = soup.find_all(\"div\",{'class':'paging clearfix'})\n",
    "  paging_link = paging[0].find_all('a',{'class':'paging__link'})\n",
    "  #last_page = int([item.get('href').split('/')[-1] for item in paging_link][-1])\n",
    "  last_page = int([item.get('href').split('/')[-1] for item in paging_link][-1].split('=')[-1])\n",
    "\n",
    "  data = []\n",
    "  for page in range(1, last_page+1):\n",
    "    url = f\"https://indeks.kompas.com/?site=all&date=2023-06-28&page={page}\"\n",
    "    page = urlopen(url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    articles = soup.find_all(\"div\", {\"class\":\"article__list clearfix\"})\n",
    "    for article in articles:\n",
    "      document = {\n",
    "          \"Title\": article.find('h3', {'class':'article__title article__title--medium'}).text,\n",
    "          \"Url\": article.find('div', {'class':'article__list__title'}).find('a')['href'],\n",
    "          \"Published_at\": article.find('div', {'class':'article__date'}).text,\n",
    "          \"Tumb\": article.find('div', {'class':'article__asset'}).find('img')['src']\n",
    "          }\n",
    "      data.append(document)\n",
    "  kompas_db.insert_many(data)\n",
    "\n",
    "  return data\n",
    "\n",
    "def tribun_crawl():\n",
    "  url = \"https://www.tribunnews.com/index-news?date=2023-6-28&page=4\"\n",
    "  page = urlopen(url)\n",
    "  html = page.read().decode(\"utf-8\")\n",
    "  soup = BeautifulSoup(html, \"html.parser\")\n",
    "  paging = soup.find_all(\"div\", {\"class\":\"paging\"})\n",
    "  paging_link = paging[0].find_all(\"a\")\n",
    "  last_page = int([item.get('href') for item in paging_link][-1].split('=')[-1])\n",
    "\n",
    "  data = []\n",
    "  for page in range(1, last_page+1):\n",
    "      url = f\"https://www.tribunnews.com/index-news?date=2023-6-28&page={page}\"\n",
    "      page = urlopen(url)\n",
    "      html = page.read().decode(\"utf-8\")\n",
    "      soup = BeautifulSoup(html, \"html.parser\")\n",
    "      articles = soup.find_all(\"li\", {\"class\":\"ptb15\"})\n",
    "\n",
    "      for article in articles:\n",
    "        document = {\n",
    "            \"Title\": article.find(\"h3\", {\"class\":\"f16 fbo\"}).find('a')['title'],\n",
    "            \"Url\": article.find(\"h3\", {\"class\":\"f16 fbo\"}).find('a')['href'],\n",
    "            \"Published_at\": article.find(\"time\", {\"class\":\"grey\"}).text\n",
    "            }\n",
    "        data.append(document)\n",
    "  tribun_db.insert_many(data)\n",
    "\n",
    "  return data\n",
    "\n",
    "def detik_crawl():\n",
    "  url = f\"https://news.detik.com/indeks/3?date=06/28/2023\"\n",
    "  page = urlopen(url)\n",
    "  html = page.read().decode(\"utf-8\")\n",
    "  soup = BeautifulSoup(html, \"html.parser\")\n",
    "  paging = soup.find_all(\"div\", {\"class\":\"pagination text-center mgt-16 mgb-16\"})\n",
    "  paging_link = paging[0].find_all(\"a\", {\"class\":\"pagination__item\"})\n",
    "  last_page = [int(re.search(r\"/indeks/(\\d+)\\?\", item['href']).group(1)) for item in paging_link if re.search(r\"/indeks/(\\d+)\\?\", item['href'])]\n",
    "\n",
    "  data = []\n",
    "  for page in range(1, max(last_page)+1):\n",
    "    url = f\"https://news.detik.com/indeks/{page}?date=06/28/2023\"\n",
    "    page = urlopen(url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    articles = soup.find_all(\"article\", {\"class\":\"list-content__item\"})\n",
    "\n",
    "    for article in articles:\n",
    "      document = {\n",
    "        \"Title\": article.find('h3', {'class':'media__title'}).text.strip().title(),\n",
    "        \"Url\": article.find('h3', {'class':'media__title'}).find('a')['href'],\n",
    "        \"Published_at\": article.find('div', {'class':'media__date'}).text,\n",
    "        \"Tumb\": article.find('div', {'class':'media__image'}).find('a')['href']\n",
    "      }\n",
    "      data.append(document)\n",
    "  detik_db.insert_many(data)\n",
    "\n",
    "  return data\n",
    "\n",
    "def cnn_crawl():\n",
    "  url = f\"https://www.cnnindonesia.com/nasional/indeks/3?date=2023/06/28\"\n",
    "  page = urlopen(url)\n",
    "  html = page.read().decode(\"utf-8\")\n",
    "  soup = BeautifulSoup(html, \"html.parser\")\n",
    "  hal = soup.find_all(\"a\",{\"dtr-evt\":\"halaman\"})\n",
    "  last = []\n",
    "  for h in hal:\n",
    "    try:\n",
    "      last_ = int(h[\"dtr-act\"].split(' ')[1])\n",
    "      last.append(last_)\n",
    "    except:\n",
    "      pass\n",
    "  data = []\n",
    "\n",
    "  for page in range(1, max(last)+1):\n",
    "    url = f\"https://www.cnnindonesia.com/nasional/indeks/3/{page}?date=2023/06/28\"\n",
    "    page = urlopen(url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    articles = soup.find_all('article', {'class':''})\n",
    "    for article in articles:\n",
    "      document = {\n",
    "        \"Title\": article.find('h2', {'class':'title'}).text,\n",
    "        \"Url\": article.find('a')['href'],\n",
    "        \"Published_at\": article.find('span', {'class':'date'}).find(string=lambda text: isinstance(text, Comment)),\n",
    "        \"Tumb\": article.find('span', {'class':'ratiobox ratio_16_9 box_img'}).find('img')['src']\n",
    "        }\n",
    "      data.append(document)\n",
    "    \n",
    "  cnn_db.insert_many(data)\n",
    "  return data\n",
    "\n",
    "\n",
    "def okezone_crawl():\n",
    "  url = f\"https://news.okezone.com/indeks/2023/06/28/40\"\n",
    "  headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\" }\n",
    "  req = Request(url, headers=headers) \n",
    "  page = urlopen(req)\n",
    "  html = page.read().decode(\"utf-8\")\n",
    "  soup = BeautifulSoup(html, \"html.parser\")\n",
    "  paging = soup.find('div', {'class':'pagination-komentar'})\n",
    "  links = paging.find_all('a')\n",
    "  last =[int(link['data-ci-pagination-page']) for link in links]\n",
    "  hal = max(last)\n",
    "  data = []\n",
    "  \n",
    "  for page in range(1, hal+1):\n",
    "    url = f\"https://news.okezone.com/indeks/2023/06/28/{page}\"\n",
    "    headers = {\n",
    "      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    req = Request(url, headers=headers) \n",
    "    page = urlopen(req)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    articles = soup.find_all('li', {'class':'col-md-12 p-nol m-nol hei-index'})\n",
    "    \n",
    "    for article in articles:\n",
    "      document = {\n",
    "        \"Title\": article.find('h4', {'class':'f17'}).text.strip().title(),\n",
    "        \"Url\": article.find('h4', {'class':'f17'}).find('a')['href'],\n",
    "        \"Published_at\": article.find('time', {'class':'category-hardnews f12'}).text.strip().splitlines()[1]\n",
    "        }\n",
    "      data.append(document)\n",
    "\n",
    "  okezone_db.insert_many(data)\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://indeks.kompas.com/?site=all&date=2023-06-28\"\n",
    "#urll = \"https://www.tribunnews.com/index-news?date=2023-6-28&page=4\"\n",
    "kompas = kompas_crawl()\n",
    "tribun = tribun_crawl()\n",
    "detik = detik_crawl()\n",
    "cnn = cnn_crawl()\n",
    "okezone = okezone_crawl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
